{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf777d",
   "metadata": {},
   "source": [
    "You are evaluating a candidate sentiment model to replace a production baseline. Your goal is to determine whether this model should ship.\n",
    "\n",
    "‚ÄúShip‚Äù means: we would choose the candidate model over the baseline for deployment based on the evidence you collect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cfc1c7",
   "metadata": {},
   "source": [
    "### Step 1 - Install the required dependencies, set up W&B and make sure the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1012c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Nutcracker/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb datasets transformers evaluate tqdm emoji regex pandas pyarrow scikit-learn nbformat torch\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import wandb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01639808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /Users/improvise/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meames_shi\u001b[0m (\u001b[33meames_shi-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262b991",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f18b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8e44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and config:\n",
    "import re, regex, emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# WANDB CONFIG\n",
    "PROJECT = \"mlip-lab4-slices-2026\"\n",
    "ENTITY = None\n",
    "RUN_NAME = \"baseline_vs_candidate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3a6beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to compare\n",
    "MODELS = {\n",
    "    \"baseline_model\": \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    \"candidate_model\":    \"LYTinn/finetuning-sentiment-model-tweet-gpt2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434c2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label normalization for tweet_eval (0/1/2 -> string labels)\n",
    "ID2LABEL = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "# Many HF sentiment models output labels like LABEL_0 / LABEL_1 / LABEL_2\n",
    "HF_LABEL_MAP = {\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\": \"positive\"}\n",
    "\n",
    "USE_HF_DATASET = True  # set False to use tweets.csv fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289dcac3",
   "metadata": {},
   "source": [
    "### Step 2 - Load a dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9575ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45615/45615 [00:00<00:00, 663432.01 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12284/12284 [00:00<00:00, 3495917.38 examples/s]\n",
      "Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:00<00:00, 1176522.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6d30989d-5147-469c-bb50-3bfdc8612d6c",
       "rows": [
        [
         "0",
         "@user @user what do these '1/2 naked pics' have to do with anything? They're not even like that.",
         "neutral"
        ],
        [
         "1",
         "OH: ‚ÄúI had a blue penis while I was this‚Äù [playing with Google Earth VR]",
         "neutral"
        ],
        [
         "2",
         "@user @user That's coming, but I think the victims are going to be Medicaid recipients.",
         "neutral"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  @user @user what do these '1/2 naked pics' hav...  neutral\n",
       "1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...  neutral\n",
       "2  @user @user That's coming, but I think the vic...  neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_HF_DATASET:\n",
    "    ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "    df = pd.DataFrame(ds[\"test\"]).head(500).copy()\n",
    "    df[\"label\"] = df[\"label\"].map(ID2LABEL)\n",
    "else:\n",
    "    df = pd.read_csv(\"tweets.csv\")\n",
    "    # Ensure it has 'text' and 'label' columns\n",
    "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "    assert {\"text\",\"label\"}.issubset(df.columns), \"tweets.csv must include text,label\"\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.lower()\n",
    "\n",
    "df = df[[\"text\",\"label\"]].dropna().reset_index(drop=True)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0546f1",
   "metadata": {},
   "source": [
    "### Step 3 - Define Failure-Relevant Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089146d4",
   "metadata": {},
   "source": [
    "#TODO:\n",
    "In this step, you will create **at least 5** metadata columns that help you slice and analyze model behavior in Weights & Biases (W&B).\n",
    "These metadata columns should **capture meaningful properties of the data or model behavior that may influence performance**. You can define them using:\n",
    "\n",
    "1. Value matching (e.g., tweets containing hashtags or mentions)\n",
    "2. Regex patterns (e.g., negation words, strong sentiment terms like love or hate)\n",
    "3. Heuristics (e.g., emoji count, all-caps text, tweet length buckets)\n",
    "\n",
    "Each metadata column should correspond to a potential hypothesis about when or why a model might succeed or fail.\n",
    "These columns will be propagated through inference and included in the final predictions_table logged to W&B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62499536",
   "metadata": {},
   "source": [
    "After inference, your W&B table (df_long) will contain:\n",
    "- The original tweet text\n",
    "- Ground-truth sentiment labels\n",
    "- Model predictions and confidence scores\n",
    "- All metadata columns you defined for slicing\n",
    "\n",
    "You will use these metadata fields in the W&B UI (via the ‚ûï Filter option) to:\n",
    "- Create slices of the data\n",
    "- Compare model behavior across slices\n",
    "- Identify patterns, weaknesses, or regressions that are not visible in overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fd5775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/t2wnd4h911v09vtv543hpkg80000gn/T/ipykernel_28759/444132091.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_negation\"] = df[\"text\"].str.contains(r\"\\b(not|never|no)\\b\", regex=True)\n",
      "/var/folders/kd/t2wnd4h911v09vtv543hpkg80000gn/T/ipykernel_28759/444132091.py:20: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_strong_emotion\"] = df[\"text\"].str.contains(r\"\\b(much|very|too|deeply)\\b\", regex = True) # strong emotions helps model decide\n",
      "/var/folders/kd/t2wnd4h911v09vtv543hpkg80000gn/T/ipykernel_28759/444132091.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_turning\"] = df[\"text\"].str.contains(r\"\\b(but|however|though|although|while|whereas)\\b\", regex=True) # constrast words contain complex emotions\n",
      "/var/folders/kd/t2wnd4h911v09vtv543hpkg80000gn/T/ipykernel_28759/444132091.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_affirmation\"] = df[\"text\"].str.contains(r\"\\b(yes|love|sure|great|)\\b\", regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 3 ‚Äì Add slicing metadata (text-only)\n",
    "\n",
    "# TODO: add your own hypothesis-driven metadata here. \n",
    "# Here are examples of the kinds of metadata columns you can add & analyse.\n",
    "# Categories you can explore are: Linguistic, Emotional/semantic, Model-behavioral. Do not reuse the ones given below.\n",
    "def count_emojis(text: str) -> int:\n",
    "    return sum(ch in emoji.EMOJI_DATA for ch in str(text))\n",
    "\n",
    "df[\"emoji_count\"] = df[\"text\"].apply(count_emojis).astype(int)\n",
    "df[\"has_hashtag\"] = df[\"text\"].str.contains(r\"#\\w+\", regex=True)\n",
    "df[\"has_mention\"] = df[\"text\"].str.contains(r\"@\\w+\", regex=True)\n",
    "df[\"has_negation\"] = df[\"text\"].str.contains(r\"\\b(not|never|no)\\b\", regex=True)\n",
    "df[\"length_bucket\"] = pd.cut(\n",
    "    df[\"text\"].str.len(),\n",
    "    bins=[0, 50, 100, 200, 1000, 10_000],\n",
    "    labels=[\"0-50\", \"51-100\", \"101-200\", \"201-1000\", \"1001+\"],\n",
    "    include_lowest=True\n",
    ").astype(str)\n",
    "\n",
    "df[\"has_strong_emotion\"] = df[\"text\"].str.contains(r\"\\b(much|very|too|deeply)\\b\", regex = True) # strong emotions helps model decide\n",
    "df[\"has_turning\"] = df[\"text\"].str.contains(r\"\\b(but|however|though|although|while|whereas)\\b\", regex=True) # constrast words contain complex emotions\n",
    "df[\"has_affirmation\"] = df[\"text\"].str.contains(r\"\\b(yes|love|sure|great|)\\b\", regex=True)\n",
    "df[\"avg_length_per_sentence\"] = df[\"text\"].apply( \n",
    "    lambda text: np.mean([len(s) for s in text.split(\".\") if s.strip()])                                             \n",
    ")\n",
    "df[\"has_question\"] = df[\"text\"].str.contains(r\"\\?\", regex=True)\n",
    "df[\"has_all_caps_word\"] = df[\"text\"].str.contains(r\"\\b[A-Z]{2,}\\b\", regex=True)\n",
    "\n",
    "\n",
    "# Example slice definitions (you'll create more later)\n",
    "def get_slices(df_any: pd.DataFrame):\n",
    "    return {\n",
    "        # \"emoji_gt3\":            df_any[\"emoji_count\"] > 3\n",
    "        # , \"has_negation\":       df_any[\"has_negation\"] == True\n",
    "        # , \"has_hashtag\":        df_any[\"has_hashtag\"] == True\n",
    "        \"has_strong_emotion\": df_any[\"has_strong_emotion\"] == True\n",
    "        , \"has_turning\":        df_any[\"has_turning\"] == True\n",
    "        , \"has_question\":       df_any[\"has_question\"] == True \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a75f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.0\n",
      "transformers: 4.57.3\n",
      "CUDA available: False\n",
      "MPS available:  True\n",
      "Python: /opt/anaconda3/envs/Nutcracker/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Transformers requires a backend (PyTorch/TensorFlow/Flax). We'll use PyTorch.\n",
    "try:\n",
    "    import torch, transformers, sys\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"transformers:\", transformers.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"MPS available: \", torch.mps.is_available())\n",
    "    print(\"Python:\", sys.executable)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Install PyTorch before proceeding: pip install torch torchvision torchaudio\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ec371",
   "metadata": {},
   "source": [
    "###  Step 4 ‚Äì Run Inference (Two Models)\n",
    "\n",
    "In this step, you'll use two HuggingFace sentiment analysis models to run inference on your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89f69d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n",
      "Infer: cardiffnlp/twitter-roberta-base-sentiment-latest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:18<00:00, 26.87it/s]\n",
      "Device set to use mps\n",
      "Infer: LYTinn/finetuning-sentiment-model-tweet-gpt2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:15<00:00, 31.82it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emoji_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_hashtag",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_mention",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_negation",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "length_bucket",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_strong_emotion",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_turning",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_affirmation",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "avg_length_per_sentence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_question",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_all_caps_word",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "conf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ex_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8e158efe-8db7-4d1c-bb3f-2008d47eb690",
       "rows": [
        [
         "0",
         "@user @user what do these '1/2 naked pics' have to do with anything? They're not even like that.",
         "neutral",
         "0",
         "False",
         "True",
         "True",
         "51-100",
         "False",
         "False",
         "True",
         "95.0",
         "True",
         "False",
         "baseline_model",
         "negative",
         "0.8047258853912354",
         "113"
        ],
        [
         "1",
         "OH: ‚ÄúI had a blue penis while I was this‚Äù [playing with Google Earth VR]",
         "neutral",
         "0",
         "False",
         "False",
         "False",
         "51-100",
         "False",
         "True",
         "True",
         "72.0",
         "False",
         "True",
         "baseline_model",
         "neutral",
         "0.8669493794441223",
         "363"
        ],
        [
         "2",
         "@user @user That's coming, but I think the victims are going to be Medicaid recipients.",
         "neutral",
         "0",
         "False",
         "True",
         "False",
         "51-100",
         "False",
         "True",
         "True",
         "86.0",
         "False",
         "False",
         "baseline_model",
         "neutral",
         "0.7637245059013367",
         "102"
        ],
        [
         "3",
         "I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user",
         "positive",
         "0",
         "True",
         "True",
         "False",
         "51-100",
         "False",
         "False",
         "True",
         "83.0",
         "False",
         "False",
         "baseline_model",
         "positive",
         "0.774046778678894",
         "305"
        ],
        [
         "4",
         "@user Wow,first Hugo Chavez and now Fidel Castro. Danny Glover, Michael Moore, Oliver Stone, and Sean Penn are running out of heroes.",
         "negative",
         "0",
         "False",
         "True",
         "False",
         "101-200",
         "False",
         "False",
         "True",
         "65.5",
         "False",
         "False",
         "baseline_model",
         "neutral",
         "0.4163973331451416",
         "160"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_negation</th>\n",
       "      <th>length_bucket</th>\n",
       "      <th>has_strong_emotion</th>\n",
       "      <th>has_turning</th>\n",
       "      <th>has_affirmation</th>\n",
       "      <th>avg_length_per_sentence</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_all_caps_word</th>\n",
       "      <th>model</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>ex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>51-100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>95.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804726</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51-100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.866949</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>51-100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>86.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.763725</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>51-100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>101-200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>65.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.416397</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  emoji_count  \\\n",
       "0  @user @user what do these '1/2 naked pics' hav...   neutral            0   \n",
       "1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...   neutral            0   \n",
       "2  @user @user That's coming, but I think the vic...   neutral            0   \n",
       "3  I think I may be finally in with the in crowd ...  positive            0   \n",
       "4  @user Wow,first Hugo Chavez and now Fidel Cast...  negative            0   \n",
       "\n",
       "   has_hashtag  has_mention  has_negation length_bucket  has_strong_emotion  \\\n",
       "0        False         True          True        51-100               False   \n",
       "1        False        False         False        51-100               False   \n",
       "2        False         True         False        51-100               False   \n",
       "3         True         True         False        51-100               False   \n",
       "4        False         True         False       101-200               False   \n",
       "\n",
       "   has_turning  has_affirmation  avg_length_per_sentence  has_question  \\\n",
       "0        False             True                     95.0          True   \n",
       "1         True             True                     72.0         False   \n",
       "2         True             True                     86.0         False   \n",
       "3        False             True                     83.0         False   \n",
       "4        False             True                     65.5         False   \n",
       "\n",
       "   has_all_caps_word           model      pred      conf  ex_id  \n",
       "0              False  baseline_model  negative  0.804726    113  \n",
       "1               True  baseline_model   neutral  0.866949    363  \n",
       "2              False  baseline_model   neutral  0.763725    102  \n",
       "3              False  baseline_model  positive  0.774047    305  \n",
       "4              False  baseline_model   neutral  0.416397    160  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def run_pipeline(model_id: str, texts: list[str]):\n",
    "    clf = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model_id,\n",
    "        truncation=True,\n",
    "        max_length=128,     # avoid truncation warnings\n",
    "        framework=\"pt\",\n",
    "        device= \"mps\"           # CPU\n",
    "    )\n",
    "    # (Optional) sanity check label mapping for this model\n",
    "    # print(model_id, clf.model.config.id2label)\n",
    "\n",
    "    preds, confs = [], []\n",
    "    for t in tqdm(texts, desc=f\"Infer: {model_id}\"):\n",
    "        out = clf(t)[0]\n",
    "        lbl = HF_LABEL_MAP.get(out[\"label\"], out[\"label\"])\n",
    "        preds.append(lbl)\n",
    "        confs.append(float(out[\"score\"]))\n",
    "    return preds, confs\n",
    "\n",
    "pred_frames = []\n",
    "texts = df[\"text\"].tolist()\n",
    "\n",
    "for model_name, model_id in MODELS.items():\n",
    "    yhat, conf = run_pipeline(model_id, texts)\n",
    "    tmp = df.copy()\n",
    "    tmp[\"model\"] = model_name\n",
    "    tmp[\"pred\"] = yhat\n",
    "    tmp[\"conf\"] = conf\n",
    "    pred_frames.append(tmp)\n",
    "\n",
    "df_long = pd.concat(pred_frames, ignore_index=True)\n",
    "\n",
    "# Add a stable example id so reshaping won't silently drop duplicates\n",
    "df_long[\"ex_id\"] = df_long.groupby([\"text\", \"label\"]).ngroup()\n",
    "\n",
    "df_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d189f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ex_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_strong_emotion",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_turning",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_affirmation",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "avg_length_per_sentence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_question",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "has_all_caps_word",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "conf_baseline_model",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "conf_candidate_model",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pred_baseline_model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred_candidate_model",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bef4b064-8fea-4fa3-aac8-895272ae05bc",
       "rows": [
        [
         "0",
         "0",
         "\"Fatty Kim The Third\" üò≠üò≠üò≠",
         "neutral",
         "False",
         "False",
         "True",
         "25.0",
         "False",
         "False",
         "0.48625168204307556",
         "0.978986918926239",
         "neutral",
         "neutral"
        ],
        [
         "1",
         "1",
         "\"Focusing on [alt rightists'] respectability...makes white supremacy appear normal and acceptable.\"",
         "neutral",
         "False",
         "False",
         "True",
         "31.666666666666668",
         "False",
         "False",
         "0.5735722184181213",
         "0.9997276663780212",
         "negative",
         "neutral"
        ],
        [
         "2",
         "2",
         "\"Kim Fatty the Third\"",
         "negative",
         "False",
         "False",
         "True",
         "21.0",
         "False",
         "False",
         "0.8497324585914612",
         "0.9377092123031616",
         "neutral",
         "neutral"
        ],
        [
         "3",
         "3",
         "\"We have lost everything\": Syrians return to ravaged Aleppo, @user reports. by #AP via @user",
         "neutral",
         "False",
         "False",
         "True",
         "45.5",
         "False",
         "True",
         "0.7519552111625671",
         "0.9942439198493958",
         "negative",
         "positive"
        ],
        [
         "4",
         "4",
         "\"who's the most wiped out white boy? Zac Efron! Zac Efron!\"",
         "neutral",
         "False",
         "False",
         "True",
         "59.0",
         "True",
         "False",
         "0.5612325072288513",
         "0.906539797782898",
         "neutral",
         "positive"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>has_strong_emotion</th>\n",
       "      <th>has_turning</th>\n",
       "      <th>has_affirmation</th>\n",
       "      <th>avg_length_per_sentence</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_all_caps_word</th>\n",
       "      <th>conf_baseline_model</th>\n",
       "      <th>conf_candidate_model</th>\n",
       "      <th>pred_baseline_model</th>\n",
       "      <th>pred_candidate_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Fatty Kim The Third\" üò≠üò≠üò≠</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.486252</td>\n",
       "      <td>0.978987</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Focusing on [alt rightists'] respectability.....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.573572</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Kim Fatty the Third\"</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.849732</td>\n",
       "      <td>0.937709</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"We have lost everything\": Syrians return to r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751955</td>\n",
       "      <td>0.994244</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"who's the most wiped out white boy? Zac Efron...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561233</td>\n",
       "      <td>0.906540</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id                                               text     label  \\\n",
       "0      0                          \"Fatty Kim The Third\" üò≠üò≠üò≠   neutral   \n",
       "1      1  \"Focusing on [alt rightists'] respectability.....   neutral   \n",
       "2      2                              \"Kim Fatty the Third\"  negative   \n",
       "3      3  \"We have lost everything\": Syrians return to r...   neutral   \n",
       "4      4  \"who's the most wiped out white boy? Zac Efron...   neutral   \n",
       "\n",
       "   has_strong_emotion  has_turning  has_affirmation  avg_length_per_sentence  \\\n",
       "0               False        False             True                25.000000   \n",
       "1               False        False             True                31.666667   \n",
       "2               False        False             True                21.000000   \n",
       "3               False        False             True                45.500000   \n",
       "4               False        False             True                59.000000   \n",
       "\n",
       "   has_question  has_all_caps_word  conf_baseline_model  conf_candidate_model  \\\n",
       "0         False              False             0.486252              0.978987   \n",
       "1         False              False             0.573572              0.999728   \n",
       "2         False              False             0.849732              0.937709   \n",
       "3         False               True             0.751955              0.994244   \n",
       "4          True              False             0.561233              0.906540   \n",
       "\n",
       "  pred_baseline_model pred_candidate_model  \n",
       "0             neutral              neutral  \n",
       "1            negative              neutral  \n",
       "2             neutral              neutral  \n",
       "3            negative             positive  \n",
       "4             neutral             positive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4.5 ‚Äì Wide-format Table for Model Comparison (Optional but recommended)\n",
    "# One row per tweet, with baseline + candidate predictions in columns\n",
    "# TODO: Replace with your metadata\n",
    "df_wide = df_long.pivot_table(\n",
    "    index=[\n",
    "        \"ex_id\", \"text\", \"label\",\n",
    "        \"has_strong_emotion\", \"has_turning\", \"has_affirmation\", \"avg_length_per_sentence\", \"has_question\", \"has_all_caps_word\"\n",
    "    ],\n",
    "    columns=\"model\",\n",
    "    values=[\"pred\", \"conf\"],\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Flatten column names (e.g., pred_baseline_model, conf_candidate_model)\n",
    "df_wide.columns = [\"_\".join([c for c in col if c]).strip(\"_\") for col in df_wide.columns]\n",
    "\n",
    "df_wide.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dedaa9",
   "metadata": {},
   "source": [
    "### Step 5: Compute Metrics (Accuracy + Slice Accuracy + Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77d0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Edit to work for your slices\n",
    "\n",
    "#compute metrics model-wise\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(list(y_true), list(y_pred))\n",
    "\n",
    "# Overall accuracy by model (df_long: one row per (tweet, model))\n",
    "overall = df_long.groupby(\"model\").apply(\n",
    "    lambda g: compute_accuracy(g[\"label\"], g[\"pred\"]),\n",
    "    include_groups=False\n",
    ")\n",
    "\n",
    "# Slice accuracy table (uses df_long masks)\n",
    "slice_table = wandb.Table(columns=[\"slice\", \"model\", \"accuracy\"])\n",
    "slice_metrics = {}\n",
    "\n",
    "for slice_name, mask in get_slices(df_long).items():\n",
    "    slice_metrics[slice_name] = {}\n",
    "    for model_name, g in df_long[mask].groupby(\"model\"):\n",
    "        acc = float(compute_accuracy(g[\"label\"], g[\"pred\"]))\n",
    "        slice_table.add_data(slice_name, model_name, acc)\n",
    "        slice_metrics[slice_name][model_name] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596b544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression rate: 0.408\n",
      "Improvement rate: 0.108\n",
      "Confident regression rate: 0.382\n"
     ]
    }
   ],
   "source": [
    "# TODO: Edit to work for your slices\n",
    "\n",
    "\n",
    "# Regression-aware evaluation (df_eval: one row per tweet, both model outputs) \n",
    "# A regression is when the candidate gets something wrong that the baseline got right.\n",
    "BASELINE = \"baseline_model\"\n",
    "CANDIDATE = \"candidate_model\"\n",
    "\n",
    "# Ensure ex_id exists (safe even if it already exists)\n",
    "df_long = df_long.copy()\n",
    "if \"ex_id\" not in df_long.columns:\n",
    "    df_long[\"ex_id\"] = df_long.groupby([\"text\", \"label\"]).ngroup()\n",
    "\n",
    "# Build df_eval with metadata carried through\n",
    "df_eval = (\n",
    "    df_long.pivot_table(\n",
    "        index=[\n",
    "            \"ex_id\", \"text\", \"label\",\n",
    "            \"has_strong_emotion\", \"has_turning\", \"has_affirmation\", \"avg_length_per_sentence\", \"has_question\", \"has_all_caps_word\"\n",
    "        ],\n",
    "        columns=\"model\",\n",
    "        values=[\"pred\", \"conf\"],\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten column names (pred_baseline_model, conf_candidate_model, etc.)\n",
    "df_eval.columns = [\"_\".join([c for c in col if c]).strip(\"_\") for col in df_eval.columns]\n",
    "\n",
    "# Correctness flags\n",
    "df_eval[\"baseline_correct\"]  = df_eval[f\"pred_{BASELINE}\"] == df_eval[\"label\"]\n",
    "df_eval[\"candidate_correct\"] = df_eval[f\"pred_{CANDIDATE}\"] == df_eval[\"label\"]\n",
    "\n",
    "# Regression / improvement flags\n",
    "df_eval[\"regressed\"]   = df_eval[\"baseline_correct\"] & ~df_eval[\"candidate_correct\"]\n",
    "df_eval[\"improved\"]    = ~df_eval[\"baseline_correct\"] & df_eval[\"candidate_correct\"]\n",
    "df_eval[\"both_wrong\"]  = ~df_eval[\"baseline_correct\"] & ~df_eval[\"candidate_correct\"]\n",
    "df_eval[\"both_correct\"]= df_eval[\"baseline_correct\"] & df_eval[\"candidate_correct\"]\n",
    "\n",
    "# Confidence-conditional regression (candidate is confident AND worse than baseline)\n",
    "df_eval[\"confident_regression\"] = df_eval[\"regressed\"] & (df_eval[f\"conf_{CANDIDATE}\"] >= 0.8)\n",
    "\n",
    "# Global regression metrics\n",
    "regression_rate = float(df_eval[\"regressed\"].mean())\n",
    "improvement_rate = float(df_eval[\"improved\"].mean())\n",
    "conf_reg_rate = float(df_eval[\"confident_regression\"].mean())\n",
    "\n",
    "print(\"Regression rate:\", regression_rate)\n",
    "print(\"Improvement rate:\", improvement_rate)\n",
    "print(\"Confident regression rate:\", conf_reg_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e21e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Edit to work with your slices\n",
    "\n",
    "# Define slices on df_eval (must use columns that exist in df_eval)\n",
    "def get_slices_eval(df_any):\n",
    "    return {\n",
    "        \"has_strong_emotion\": df_any[\"has_strong_emotion\"] == True\n",
    "        , \"has_turning\":        df_any[\"has_turning\"] == True\n",
    "        , \"has_question\":       df_any[\"has_question\"] == True \n",
    "    }\n",
    "\n",
    "# Slice-level regression metrics table\n",
    "reg_table = wandb.Table(columns=[\"slice\", \"metric\", \"value\"])\n",
    "reg_metrics = {}\n",
    "\n",
    "for slice_name, mask in get_slices_eval(df_eval).items():\n",
    "    g = df_eval[mask]\n",
    "    if len(g) == 0:\n",
    "        continue\n",
    "\n",
    "    reg = float(g[\"regressed\"].mean())\n",
    "    imp = float(g[\"improved\"].mean())\n",
    "    conf_reg = float(g[\"confident_regression\"].mean())\n",
    "\n",
    "    reg_table.add_data(slice_name, \"regression_rate\", reg)\n",
    "    reg_table.add_data(slice_name, \"improvement_rate\", imp)\n",
    "    reg_table.add_data(slice_name, \"confident_regression_rate\", conf_reg)\n",
    "\n",
    "    reg_metrics[slice_name] = {\n",
    "        \"regression_rate\": reg,\n",
    "        \"improvement_rate\": imp,\n",
    "        \"conf_reg_rate\": conf_reg\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7843a",
   "metadata": {},
   "source": [
    "# Step 6 ‚Äî #TODO: Log to W&B & Analyse Slices\n",
    "# (Make sure PROJECT/ENTITY/RUN_NAME exist from Step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "425dd4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/improvise/Desktop/PostGrad/02 Courses/03 Spring 2026/17645 1 - Machine Learning Production/Lab/Lab#4/cmu-mlip-model-testing-lab/wandb/run-20260203_203303-rh5oa3uc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc' target=\"_blank\">baseline_vs_candidate</a></strong> to <a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc' target=\"_blank\">https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run URL: https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>baseline_model_accuracy</td><td>0.698</td></tr><tr><td>candidate_model_accuracy</td><td>0.398</td></tr><tr><td>confident_regression_rate</td><td>0.382</td></tr><tr><td>improvement_rate</td><td>0.108</td></tr><tr><td>regression_rate</td><td>0.408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline_vs_candidate</strong> at: <a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc' target=\"_blank\">https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rh5oa3uc</a><br> View project at: <a href='https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/eames_shi-carnegie-mellon-university/mlip-lab4-slices-2026</a><br>Synced 4 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260203_203303-rh5oa3uc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Log to W&B\n",
    "\n",
    "PROJECT = \"mlip-lab4-slices-2026\"\n",
    "ENTITY = None\n",
    "RUN_NAME = \"baseline_vs_candidate\"\n",
    "run = wandb.init(project=PROJECT, entity=ENTITY, name=RUN_NAME)\n",
    "wandb.log({\"predictions_table\": wandb.Table(dataframe=df_long)})\n",
    "wandb.log({\"slice_metrics\": slice_table})\n",
    "wandb.log({\"regression_metrics\": reg_table})\n",
    "wandb.log({\n",
    "    \"df_eval\": wandb.Table(dataframe=df_eval)\n",
    "})\n",
    "for model_name, acc in overall.items():\n",
    "    wandb.summary[f\"{model_name}_accuracy\"] = float(acc)\n",
    "wandb.summary[\"regression_rate\"] = regression_rate\n",
    "wandb.summary[\"improvement_rate\"] = improvement_rate\n",
    "wandb.summary[\"confident_regression_rate\"] = conf_reg_rate\n",
    "\n",
    "print(\"W&B run URL:\", run.get_url())\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c3b74",
   "metadata": {},
   "source": [
    "### Instructions: Exploring Slice-Based Evaluation in W&B\n",
    "\n",
    "# Purpose\n",
    "In this lab, you are evaluating a candidate sentiment model to decide whether it should replace an existing baseline (production) model.\n",
    "You have already:\n",
    "  - run both models on the same dataset\n",
    "  - logged predictions, confidence scores, and metadata to W&B\n",
    "  - created metadata that allows you to slice the data\n",
    "The most important goal is to understand when and why models behave differently.\n",
    "Overall accuracy alone is often misleading.\n",
    "\n",
    "# What to do in W&B\n",
    "1. Open your W&B run\n",
    "  - Click the project link and open the latest run.\n",
    "2. Explore the predictions table\n",
    "  - Go to the Tables tab and open predictions_table.\n",
    "  - Each row is one tweet √ó one model.\n",
    "3. Create and analyze slices (most important)\n",
    "  - Use filters to create meaningful slices \n",
    "    (e.g., negation, emojis, hashtags, long tweets).\n",
    "  - For each slice:\n",
    "    - Compare baseline vs candidate performance.\n",
    "    - Compare slice accuracy to overall accuracy.\n",
    "    - Inspect a few misclassified examples to identify patterns.\n",
    "4. Visualize slice performance\n",
    "  - Open slice_metrics.\n",
    "  - Create bar charts comparing baseline vs candidate accuracy for at least two slices.\n",
    "5. Discuss your findings with the TA\n",
    "  - Explain why slicing reveals issues that overall accuracy hides.\n",
    "  - Say whether the candidate model should be deployed and why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f83c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f8325d20-9765-493b-a48e-4521ef8d0295",
       "rows": [
        [
         "0",
         "If a tweet has turning words, the baseline model can perform really well. Strong emotion words tend to mess up the accuracy for both baseline and candidate model."
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If a tweet has turning words, the baseline mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  If a tweet has turning words, the baseline mod..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Students: replace the placeholders below with 1‚Äì2 sentence insights\n",
    "#TODO: Replace this with 1-2 sentence takeaways for each slice.\n",
    "saved_slice_notes = [\"If a tweet has turning words, the baseline model can perform really well. Strong emotion words tend to mess up the accuracy for both baseline and candidate model.\"]\n",
    "pd.DataFrame(saved_slice_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa906c",
   "metadata": {},
   "source": [
    "### Step 7 - Targeted stress testing with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396331d",
   "metadata": {},
   "source": [
    "TODO: \n",
    "In this step, you will use a Large Language Model (LLM) to generate test cases that specifically target a weakness you observed during slicing.\n",
    "\n",
    "What to do:\n",
    "1. Choose one slice where you noticed poor performance, regressions, or surprising behavior.\n",
    "2. Write a short hypothesis (1‚Äì2 sentences) explaining why the model might struggle on this slice. Example:\n",
    "‚ÄúThe model struggles with tweets that use slang and sarcasm.‚Äù\n",
    "3. Use an LLM to generate 10 test cases designed to test this hypothesis.\n",
    "These can include:\n",
    "    - subtle or ambiguous cases\n",
    "    - difficult or adversarial cases\n",
    "    - small wording changes that affect sentiment\n",
    "4. Re-run both models on the generated test cases (helper script given below.)\n",
    "5. Briefly describe what you observed to the TA:\n",
    "    - Did the same failures appear again?\n",
    "    - notice any new failure patterns?\n",
    "    - would this affect your confidence in deploying the model?\n",
    "\n",
    "Your input can be in the following format:\n",
    "\n",
    "> Examples:\n",
    "> - @user @user That‚Äôs coming, but I think the victims are going to be Medicaid recipients.\n",
    "> - I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user\n",
    "> \n",
    "> Generate more tweets using slangs.\n",
    "\n",
    "Use our provided GPTs to start the task: [llm-based-test-case-generator](https://chatgpt.com/g/g-982cylVn2-llm-based-test-case-generator). If you do not have access to GPTs, use the plain ChatGPT or other LLM providers you have access to instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49623362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Paste your 10 generated tweets here:\n",
    "\n",
    "generated_slice_description = \"The model seems to struggle with strong-emotion based tweets. Created tweets that contains strong-emotion indicators, such as `very`, `much`, `deeply`, `too`\"\n",
    "\n",
    "generated_cases = [\n",
    "    \"I‚Äôm very tired of pretending everything is fine.\"\n",
    "    , \"This means so much to me ‚Äî I can‚Äôt even explain it.\"\n",
    "    , \"That moment was just too painful to revisit.\"\n",
    "    , \"I‚Äôm deeply grateful for everyone who stood by me.\"\n",
    "    , \"I care too much and it always ends up hurting.\"\n",
    "    , \"Feeling very overwhelmed right now. Everything is hitting at once.\"\n",
    "    , \"I miss you so much it physically hurts.\"\n",
    "    , \"Deeply disappointed but not surprised.\"\n",
    "    , \"This is too good to be true ‚Äî waiting for the catch.\"\n",
    "    , \"Very proud of how far I‚Äôve come, even if no one else sees it.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ce7deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper code to run models on synthetic test cases:\n",
    "\n",
    "def run_on_generated_tests(texts, models=MODELS):\n",
    "    rows = []\n",
    "    for model_name, model_id in models.items():\n",
    "        clf = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=model_id,\n",
    "            truncation=True,\n",
    "            framework=\"pt\",\n",
    "            device= \"mps\"\n",
    "        )\n",
    "        for t in texts:\n",
    "            out = clf(t)[0]\n",
    "            rows.append({\n",
    "                \"text\": t,\n",
    "                \"model\": model_name,\n",
    "                \"pred\": HF_LABEL_MAP.get(out[\"label\"], out[\"label\"]),\n",
    "                \"conf\": float(out[\"score\"])\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4a55969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Device set to use mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "conf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ad6d8557-6e7d-4251-9584-832fb144a164",
       "rows": [
        [
         "0",
         "I‚Äôm very tired of pretending everything is fine.",
         "baseline_model",
         "negative",
         "0.8373704552650452"
        ],
        [
         "1",
         "This means so much to me ‚Äî I can‚Äôt even explain it.",
         "baseline_model",
         "positive",
         "0.9780067205429077"
        ],
        [
         "2",
         "That moment was just too painful to revisit.",
         "baseline_model",
         "negative",
         "0.9140856862068176"
        ],
        [
         "3",
         "I‚Äôm deeply grateful for everyone who stood by me.",
         "baseline_model",
         "positive",
         "0.9808639287948608"
        ],
        [
         "4",
         "I care too much and it always ends up hurting.",
         "baseline_model",
         "negative",
         "0.8624996542930603"
        ],
        [
         "5",
         "Feeling very overwhelmed right now. Everything is hitting at once.",
         "baseline_model",
         "negative",
         "0.8535544872283936"
        ],
        [
         "6",
         "I miss you so much it physically hurts.",
         "baseline_model",
         "negative",
         "0.6247614026069641"
        ],
        [
         "7",
         "Deeply disappointed but not surprised.",
         "baseline_model",
         "negative",
         "0.8203040361404419"
        ],
        [
         "8",
         "This is too good to be true ‚Äî waiting for the catch.",
         "baseline_model",
         "positive",
         "0.9622064232826233"
        ],
        [
         "9",
         "Very proud of how far I‚Äôve come, even if no one else sees it.",
         "baseline_model",
         "positive",
         "0.9792891144752502"
        ],
        [
         "10",
         "I‚Äôm very tired of pretending everything is fine.",
         "candidate_model",
         "negative",
         "0.9541921019554138"
        ],
        [
         "11",
         "This means so much to me ‚Äî I can‚Äôt even explain it.",
         "candidate_model",
         "neutral",
         "0.9997474551200867"
        ],
        [
         "12",
         "That moment was just too painful to revisit.",
         "candidate_model",
         "positive",
         "0.5576027631759644"
        ],
        [
         "13",
         "I‚Äôm deeply grateful for everyone who stood by me.",
         "candidate_model",
         "neutral",
         "0.9999861717224121"
        ],
        [
         "14",
         "I care too much and it always ends up hurting.",
         "candidate_model",
         "neutral",
         "0.9975342750549316"
        ],
        [
         "15",
         "Feeling very overwhelmed right now. Everything is hitting at once.",
         "candidate_model",
         "positive",
         "0.8930193185806274"
        ],
        [
         "16",
         "I miss you so much it physically hurts.",
         "candidate_model",
         "negative",
         "0.9717863202095032"
        ],
        [
         "17",
         "Deeply disappointed but not surprised.",
         "candidate_model",
         "neutral",
         "0.9996949434280396"
        ],
        [
         "18",
         "This is too good to be true ‚Äî waiting for the catch.",
         "candidate_model",
         "positive",
         "0.9806017875671387"
        ],
        [
         "19",
         "Very proud of how far I‚Äôve come, even if no one else sees it.",
         "candidate_model",
         "negative",
         "0.991008460521698"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>model</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I‚Äôm very tired of pretending everything is fine.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.837370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This means so much to me ‚Äî I can‚Äôt even explai...</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That moment was just too painful to revisit.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.914086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I‚Äôm deeply grateful for everyone who stood by me.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.980864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I care too much and it always ends up hurting.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feeling very overwhelmed right now. Everything...</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.853554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I miss you so much it physically hurts.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.624761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deeply disappointed but not surprised.</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.820304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This is too good to be true ‚Äî waiting for the ...</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.962206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Very proud of how far I‚Äôve come, even if no on...</td>\n",
       "      <td>baseline_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.979289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I‚Äôm very tired of pretending everything is fine.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.954192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This means so much to me ‚Äî I can‚Äôt even explai...</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>That moment was just too painful to revisit.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.557603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I‚Äôm deeply grateful for everyone who stood by me.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I care too much and it always ends up hurting.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.997534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Feeling very overwhelmed right now. Everything...</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.893019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I miss you so much it physically hurts.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.971786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Deeply disappointed but not surprised.</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This is too good to be true ‚Äî waiting for the ...</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.980602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Very proud of how far I‚Äôve come, even if no on...</td>\n",
       "      <td>candidate_model</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.991008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text            model  \\\n",
       "0    I‚Äôm very tired of pretending everything is fine.   baseline_model   \n",
       "1   This means so much to me ‚Äî I can‚Äôt even explai...   baseline_model   \n",
       "2        That moment was just too painful to revisit.   baseline_model   \n",
       "3   I‚Äôm deeply grateful for everyone who stood by me.   baseline_model   \n",
       "4      I care too much and it always ends up hurting.   baseline_model   \n",
       "5   Feeling very overwhelmed right now. Everything...   baseline_model   \n",
       "6             I miss you so much it physically hurts.   baseline_model   \n",
       "7              Deeply disappointed but not surprised.   baseline_model   \n",
       "8   This is too good to be true ‚Äî waiting for the ...   baseline_model   \n",
       "9   Very proud of how far I‚Äôve come, even if no on...   baseline_model   \n",
       "10   I‚Äôm very tired of pretending everything is fine.  candidate_model   \n",
       "11  This means so much to me ‚Äî I can‚Äôt even explai...  candidate_model   \n",
       "12       That moment was just too painful to revisit.  candidate_model   \n",
       "13  I‚Äôm deeply grateful for everyone who stood by me.  candidate_model   \n",
       "14     I care too much and it always ends up hurting.  candidate_model   \n",
       "15  Feeling very overwhelmed right now. Everything...  candidate_model   \n",
       "16            I miss you so much it physically hurts.  candidate_model   \n",
       "17             Deeply disappointed but not surprised.  candidate_model   \n",
       "18  This is too good to be true ‚Äî waiting for the ...  candidate_model   \n",
       "19  Very proud of how far I‚Äôve come, even if no on...  candidate_model   \n",
       "\n",
       "        pred      conf  \n",
       "0   negative  0.837370  \n",
       "1   positive  0.978007  \n",
       "2   negative  0.914086  \n",
       "3   positive  0.980864  \n",
       "4   negative  0.862500  \n",
       "5   negative  0.853554  \n",
       "6   negative  0.624761  \n",
       "7   negative  0.820304  \n",
       "8   positive  0.962206  \n",
       "9   positive  0.979289  \n",
       "10  negative  0.954192  \n",
       "11   neutral  0.999747  \n",
       "12  positive  0.557603  \n",
       "13   neutral  0.999986  \n",
       "14   neutral  0.997534  \n",
       "15  positive  0.893019  \n",
       "16  negative  0.971786  \n",
       "17   neutral  0.999695  \n",
       "18  positive  0.980602  \n",
       "19  negative  0.991008  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_df = run_on_generated_tests(generated_cases)\n",
    "generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5752e207",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OPTIONAL: Log synthetic test cases to W&B\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msynthetic_tests\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerated_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Nutcracker/lib/python3.12/site-packages/wandb/sdk/lib/preinit.py:36\u001b[39m, in \u001b[36mPreInitCallable.<locals>.preinit_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreinit_wrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m wandb.Error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mError\u001b[39m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Log synthetic test cases to W&B\n",
    "wandb.log({\n",
    "    \"synthetic_tests\": wandb.Table(dataframe=generated_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ca9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nutcracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
